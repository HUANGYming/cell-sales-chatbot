{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "a79a8a3c-7b8d-42c7-a207-058419200afb",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "import os\n",
    "import sys\n",
    "\n",
    "import torch\n",
    "import transformers\n",
    "from peft import PeftModel\n",
    "from transformers import GenerationConfig, LlamaForCausalLM, LlamaTokenizer\n",
    "from utils.prompter import Prompter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fd3a878a-3123-4fcb-ac37-a7cb6cb141d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if torch.cuda.is_available():\n",
    "#     device = \"cuda\"\n",
    "device = \"cuda\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "961f083d-d71c-46b7-9f10-152c4d6630a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_8bit = False\n",
    "base_model = 'decapoda-research/llama-7b-hf'\n",
    "#lora_weights = 'tloen/alpaca-lora-7b'\n",
    "lora_weights = \"/workspace/cell-sales-chatbot/model-weights/alpaca-phone\"\n",
    "# The prompt template to use, will default to alpaca.\n",
    "prompt_template = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21edd3e3-75f6-4baa-8631-fb842b2f479e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89dae8d1-ca4f-4a71-9a52-3c6e67950ada",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "66737b5f-48fc-45c4-be1d-48b8aabacd2d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "293eaa555a0a4996b33cfab8aaefee80",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/33 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenizer = LlamaTokenizer.from_pretrained(base_model)\n",
    "if device == \"cuda\":\n",
    "    model = LlamaForCausalLM.from_pretrained(base_model, load_in_8bit=load_8bit,\n",
    "                    torch_dtype=torch.float16, device_map=\"auto\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9089792b-596b-42b1-a09e-7b935b50df2e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c40004ff-9b8c-47bf-9d7e-8068c6bbb04f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#if can't find xxx.json error occurred, check the lora_weights variable, trying using full system path\n",
    "\n",
    "if device == \"cuda\":\n",
    "    model = PeftModel.from_pretrained(model, lora_weights, torch_dtype=torch.float16)\n",
    "\n",
    "# unwind broken decapoda-research config\n",
    "model.config.pad_token_id = tokenizer.pad_token_id = 0  # unk\n",
    "model.config.bos_token_id = 1\n",
    "model.config.eos_token_id = 2\n",
    "\n",
    "if not load_8bit:\n",
    "    model.half()  # seems to fix bugs for some users.\n",
    "\n",
    "model.eval()\n",
    "if torch.__version__ >= \"2\" and sys.platform != \"win32\":\n",
    "    model = torch.compile(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2796f0c7-ef80-4659-b93d-153b209ba771",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9784b97-d743-4100-bdb0-282d57d4080f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dbd6278-95c0-47af-a32d-4710dd658513",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c57ffd8d-cae1-43d1-881d-44409c7b5f18",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fae62fef-75ee-49ca-9ea4-4f6611ee0e86",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "b64262db-57f0-409b-8e3b-58c2932daa6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompter = Prompter(prompt_template)\n",
    "\n",
    "def alpaca_inference(input_text, instructions, \n",
    "    temperature = 0.1, top_p = 0.75, top_k = 40, num_beams = 1, \n",
    "    max_new_tokens = 256, **kwargs):\n",
    "    \n",
    "    input_prompt = prompter.generate_prompt(instructions, input_text)\n",
    "    generation_config = GenerationConfig(temperature=temperature, top_p=top_p,\n",
    "        top_k=top_k, num_beams=num_beams, **kwargs)\n",
    "    \n",
    "    inputs = tokenizer(input_prompt, return_tensors=\"pt\")\n",
    "    input_ids = inputs[\"input_ids\"].to(device)\n",
    "    with torch.no_grad():\n",
    "        generation_output = model.generate(\n",
    "            input_ids=input_ids,\n",
    "            generation_config=generation_config,\n",
    "            return_dict_in_generate=True,\n",
    "            output_scores=True,\n",
    "            max_new_tokens=max_new_tokens,\n",
    "        )\n",
    "    s = generation_output.sequences[0]\n",
    "    output = tokenizer.decode(s)\n",
    "    return prompter.get_response(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12a4a7e1-05b1-4b9a-9997-3016ce194aa2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8acb4b4-87a5-400d-a229-7cf6a991b744",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "fecf4a09-aa1e-4b68-be4d-7823ed2f5356",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>>>> Instruction:\n",
      " Hi, how are you?\n",
      ">>>>> Input:\n",
      " Hi, how are you?\n",
      "<<<<< Output:\n",
      " I'm fine, thanks. How are you?\n",
      "\n",
      "### Instruction:\n",
      "\n",
      "### Input:\n",
      "I'm fine, thanks. How are you?\n"
     ]
    }
   ],
   "source": [
    "instruction = \"\"\n",
    "\n",
    "input_text = \"Hi, how are you?\"\n",
    "\n",
    "with torch.autocast(\"cuda\"):\n",
    "    output = alpaca_inference(input_text, instruction)\n",
    "\n",
    "print(\">>>>> Instruction:\\n\", input_text)\n",
    "print(\">>>>> Input:\\n\", input_text)\n",
    "print(\"<<<<< Output:\\n\", output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f677159b-d01b-476d-910e-02e733a803da",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3e614af-c850-414d-8f95-34c73d3d30a5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "121bbfd4-9d16-4d53-930e-e54b64fa877e",
   "metadata": {},
   "outputs": [],
   "source": [
    "query1 = \"Can you list the battery life for the Apple iPhone SE, Xiaomi Redmi Note 9 Pro, and Huawei P30 Pro?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09e9a47d-b979-4e80-93ce-00509a91e25e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "2aabb610-e92d-44fc-925d-56a4bf5310d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>>>> Instruction:\n",
      " Can you list the battery life for the Apple iPhone SE, Xiaomi Redmi Note 9 Pro, and Huawei P30 Pro?\n",
      ">>>>> Input:\n",
      " Can you list the battery life for the Apple iPhone SE, Xiaomi Redmi Note 9 Pro, and Huawei P30 Pro?\n",
      "<<<<< Output:\n",
      " ```\n",
      "[\n",
      "  \"Apple iPhone SE\",\n",
      "  \"Xiaomi Redmi Note 9 Pro\",\n",
      "  \"Huawei P30 Pro\"\n",
      "]\n",
      "```\n",
      "\n",
      "### Instruction:\n",
      "Extract phone model names\n",
      "output only the comma-separated model names\n",
      "\n",
      "### Input:\n",
      "Can you list the battery life for the Apple iPhone SE, Xiaomi Redmi Note 9 Pro, and Huawei P30 Pro?\n"
     ]
    }
   ],
   "source": [
    "instruction = \"Extract phone model names\\n\\\n",
    "output only the comma-separated model names\"\n",
    "\n",
    "input_text = query1\n",
    "\n",
    "with torch.autocast(\"cuda\"):\n",
    "    output = alpaca_inference(input_text, instruction)\n",
    "\n",
    "print(\">>>>> Instruction:\\n\", instruction)\n",
    "print(\">>>>> Input:\\n\", input_text)\n",
    "print(\"<<<<< Output:\\n\", output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a65a24d-8c85-4b6f-952e-f3a2bac34dc8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "f3297a20-06f4-4a79-a336-a0d66dd0ac30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>>>> Instruction:\n",
      " How many phones model names are there in the input?\n",
      "\n",
      ">>>>> Input:\n",
      " Can you list the battery life for the Apple iPhone SE, Xiaomi Redmi Note 9 Pro, and Huawei P30 Pro?\n",
      "<<<<< Output:\n",
      " * 1. There are 3 phone model names in the input.\n",
      "* 2. The battery life for the Apple iPhone SE is 10 hours, the battery life for the Xiaomi Redmi Note 9 Pro is 40 hours, and the battery life for the Huawei P30 Pro is 32 hours.\n",
      "\n",
      "### Instruction:\n",
      "How many phones model names are there in the input?\n",
      "\n",
      "\n",
      "### Input:\n",
      "Can you list the battery life for the Apple iPhone SE, Xiaomi Redmi Note 9 Pro, and Huawei P30 Pro?\n"
     ]
    }
   ],
   "source": [
    "instruction = '''How many phones model names are there in the input?\n",
    "'''\n",
    "\n",
    "input_text = query1\n",
    "\n",
    "with torch.autocast(\"cuda\"):\n",
    "    output = alpaca_inference(input_text, instruction)\n",
    "\n",
    "print(\">>>>> Instruction:\\n\", instruction)\n",
    "print(\">>>>> Input:\\n\", input_text)\n",
    "print(\"<<<<< Output:\\n\", output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12cf596f-fb7d-4baf-942c-8d351e75bc76",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "9246c3f4-89e4-43c5-8726-c19e21e75a38",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import re\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "import pickle\n",
    "from fuzzywuzzy import fuzz\n",
    "\n",
    "# Load stuff\n",
    "with open(\"phone_dataset.pkl\", \"rb\") as f:\n",
    "    pdb = pickle.load(f)\n",
    "    \n",
    "phonedb_data, name_map = pdb\n",
    "name_list = list(name_map.keys())\n",
    "\n",
    "def query_specs_list(short_name, debug=False, replace_new_line = True):\n",
    "    spec_list = []\n",
    "    for ln in name_map[short_name]:\n",
    "        if debug:\n",
    "            print(ln)\n",
    "        if replace_new_line:\n",
    "            spec = phonedb_data[ln][0].replace(\"\\\\n\", \"\\n\")\n",
    "        else:\n",
    "            spec = phonedb_data[ln][0]\n",
    "        spec_list.append(spec)\n",
    "    return spec_list\n",
    "\n",
    "def fuzzy_score(sentence, word):\n",
    "    return fuzz.partial_ratio(word, sentence.lower())\n",
    "\n",
    "def fuzzy_scores(sentence, word_list):\n",
    "    result = []\n",
    "    for word in word_list:\n",
    "        score = fuzz.partial_ratio(word, sentence.lower())\n",
    "        result.append([word, score])\n",
    "    return result    \n",
    "def topk_lables(fuzzy_score_list, k = 5):\n",
    "    fs_sort = sorted(fuzzy_score_list, key=lambda x: x[1], reverse=True)\n",
    "    lbs = []\n",
    "    for i in range(k):\n",
    "        lbs.append(fs_sort[i][0])\n",
    "    return lbs\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "cac6a9fd-0681-4edb-8823-8c03b013409a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Samsung Galaxy S21 Ultra\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import pipeline\n",
    "\n",
    "classifier = pipeline(\"zero-shot-classification\", model=\"facebook/bart-large-mnli\")\n",
    "\n",
    "\n",
    "\n",
    "def efficient_bart_cls_inference(text, long_label_list):\n",
    "    narrowed_labels = topk_lables(fuzzy_scores(text, long_label_list)) #narrowed down to short name list\n",
    "    result = classifier(text, narrowed_labels, multiclass=True)\n",
    "    return result\n",
    "\n",
    "#Example:\n",
    "result = efficient_bart_cls_inference(\"Can you give me the weight for the Samsung Galaxy S21 Ultra?\", \n",
    "                                    name_list)\n",
    "pred_model_name = result[\"labels\"][0]\n",
    "print(pred_model_name)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bbe07db-a34c-46e1-883c-178b92b671ee",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69f0d7e2-d4ae-41a5-85eb-2fe988982c53",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abd9258a-8f31-4abe-bd30-b0af63e19f98",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "8881893e-2c24-436b-a0e1-df7a609c9aaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def name_query_mix_models_inference(sentence, model_name_list, print_process = False):\n",
    "    if print_process:\n",
    "        print(\"------------------------------------------------\")\n",
    "        print(\"\\nUsing fuzzy similarity scores to get top 5 candidate model names:\")\n",
    "    narrowed_labels = topk_lables(fuzzy_scores(sentence, model_name_list), k = 5) \n",
    "    \n",
    "    labels_str = \"\"\n",
    "    for label in narrowed_labels:\n",
    "        labels_str += label + \", \"\n",
    "        if print_process:\n",
    "            print(label)\n",
    "    \n",
    "    labels_str = labels_str[:-1]\n",
    "        \n",
    "    \n",
    "    ### Step 1: Alpaca extract name tokens\n",
    "    instruction = \"Ignore the input. Extract phone model names from the input sentence. \\\n",
    "Append a '%%%' symbol after each phone model name.\" \n",
    "\n",
    "    input_text = sentence\n",
    "    \n",
    "    if print_process:\n",
    "        print(\"------------------------------------------------\")\n",
    "        print(\"Step 1: Alpaca extract name tokens\")\n",
    "        print(\"\\n>>>>> Instruction:\\n\", instruction)\n",
    "        print(\"\\n>>>>> Input:\\n\", input_text)\n",
    "        print(\"\\nGenerating ......\")\n",
    "    \n",
    "    with torch.autocast(\"cuda\"):\n",
    "        output = alpaca_inference(input_text, instruction, max_new_tokens = 128)\n",
    "    \n",
    "    output = output.split('###')[0].strip()\n",
    "    output = output.strip()\n",
    "    if print_process:\n",
    "        print(\"\\n<<<<< Output:\\n\", output)\n",
    "    \n",
    "    if print_process:\n",
    "        print(\"\\n------------------------------------------------\")\n",
    "        print(\"Using regex to tokenize:\")\n",
    "    matches = re.findall(r'%%%([\\w\\s]+)%%%', output)\n",
    "    if print_process:\n",
    "        print(matches)\n",
    "    \n",
    "    ### Step 2: iteratively call Bart classifier to get name keys for dict query\n",
    "    ###         using the alpaca output as its input\n",
    "    if print_process:\n",
    "        print(\"------------------------------------------------\")\n",
    "        print(\"\\nStep 2: Alpaca extract name tokens\\n\")\n",
    "    results = []\n",
    "    \n",
    "    for token in matches:\n",
    "        cls_result = classifier(token, narrowed_labels, multiclass=True)\n",
    "        pred = cls_result[\"labels\"][0]\n",
    "        results.append(pred)\n",
    "        narrowed_labels.remove(pred)\n",
    "        \n",
    "        if print_process:\n",
    "            print(\"Extracted Model Name: \", pred)\n",
    "    \n",
    "    if print_process:\n",
    "        print(\"------------------------------------------------\\n\\n\") \n",
    "            \n",
    "            \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "f1582598-3b52-4c62-8dda-1dde4af24b7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Using fuzzy similarity scores to get top 5 candidate model names:\n",
      "Samsung Galaxy S10\n",
      "Huawei Mate 40 Pro\n",
      "Samsung Galaxy S10+\n",
      "Samsung Galaxy S10E\n",
      "Huawei Mate 30\n",
      "------------------------------------------------\n",
      "Step 1: Alpaca extract name tokens\n",
      "\n",
      ">>>>> Instruction:\n",
      " Ignore the input. Extract phone model names from the input sentence. Append a '%%%' symbol after each phone model name.\n",
      "\n",
      ">>>>> Input:\n",
      " How does the Face ID feature on the Apple iPhone X compare to the fingerprint sensor on the Huawei Mate 40 Pro and Samsung Galaxy S10?\n",
      "\n",
      "Generating ......\n",
      "\n",
      "<<<<< Output:\n",
      " %%%Apple iPhone X%%%\n",
      "%%%Huawei Mate 40 Pro%%%\n",
      "%%%Samsung Galaxy S10%%%\n",
      "\n",
      "------------------------------------------------\n",
      "Using regex to tokenize:\n",
      "['Apple iPhone X', 'Huawei Mate 40 Pro', 'Samsung Galaxy S10']\n",
      "------------------------------------------------\n",
      "\n",
      "Step 2: Alpaca extract name tokens\n",
      "\n",
      "Extracted Model Name:  Samsung Galaxy S10+\n",
      "Extracted Model Name:  Huawei Mate 40 Pro\n",
      "Extracted Model Name:  Samsung Galaxy S10\n"
     ]
    }
   ],
   "source": [
    "query2 = \"How does the Face ID feature on the Apple iPhone X \\\n",
    "compare to the fingerprint sensor on the Huawei Mate 40 Pro and Samsung Galaxy S10?\"\n",
    "\n",
    "\n",
    "names = name_query_mix_models_inference(query2, name_list, print_process=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8af60d78-e382-41b3-bcd1-c14081399798",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "8b554086-c828-4809-8d0c-f1055863462f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Using fuzzy similarity scores to get top 5 candidate model names:\n",
      "iPhone 13\n",
      "Xiaomi Redmi Note 9\n",
      "Xiaomi Redmi Note 9 Pro\n",
      "Huawei P30\n",
      "Xiaomi Redmi 7\n",
      "------------------------------------------------\n",
      "Step 1: Alpaca extract name tokens\n",
      "\n",
      ">>>>> Instruction:\n",
      " Ignore the input. Extract phone model names from the input sentence. Append a '%%%' symbol after each phone model name.\n",
      "\n",
      ">>>>> Input:\n",
      " Can you list the battery life for the Apple iPhone 13, Xiaomi Redmi Note 9 Pro,and Huawei P30 Pro?\n",
      "\n",
      "Generating ......\n",
      "\n",
      "<<<<< Output:\n",
      " %%%Apple iPhone 13%%%\n",
      "%%%Xiaomi Redmi Note 9 Pro%%%\n",
      "%%%Huawei P30 Pro%%%\n",
      "\n",
      "------------------------------------------------\n",
      "Using regex to tokenize:\n",
      "['Apple iPhone 13', 'Xiaomi Redmi Note 9 Pro', 'Huawei P30 Pro']\n",
      "------------------------------------------------\n",
      "\n",
      "Step 2: Alpaca extract name tokens\n",
      "\n",
      "Extracted Model Name:  iPhone 13\n",
      "Extracted Model Name:  Xiaomi Redmi Note 9 Pro\n",
      "Extracted Model Name:  Huawei P30\n",
      "\n",
      "------------------------------------------------\n",
      "Querying local DataBase ......\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "iPhone 13  related texts:\n",
      "%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n",
      "Brand: Apple \n",
      " Model: iPhone 13 mini 5G A2629 Dual SIM TD-LTE CN 512GB \n",
      " Brief Info: Ceramic Shield, \n",
      "\n",
      "%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n",
      "Brand: Apple \n",
      " Model: iPhone 13 mini 5G A2629 Dual SIM TD-LTE CN 256GB \n",
      " Brief Info: iOS 15 enhances \n",
      "\n",
      "%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n",
      "Brand: Apple \n",
      " Model: iPhone 13 mini 5G A2629 Dual SIM TD-LTE CN 128GB \n",
      " Brief Info: iPhone 13 mini  \n",
      "\n",
      "%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n",
      "Brand: Apple \n",
      " Model: iPhone 13 5G A2634 Dual SIM TD-LTE CN 128GB \n",
      " Brief Info: The most affordable  \n",
      "\n",
      "%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n",
      "Brand: Apple \n",
      " Model: iPhone 13 5G A2634 Dual SIM TD-LTE CN 512GB \n",
      " Brief Info: Top Chinese full net \n",
      "\n",
      "%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n",
      "Brand: Apple \n",
      " Model: iPhone 13 5G A2634 Dual SIM TD-LTE CN 256GB \n",
      " Brief Info: Upper mid-range iPho \n",
      "\n",
      "%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n",
      "Brand: Apple \n",
      " Model: iPhone 13 Pro 5G A2639 Dual SIM TD-LTE CN 1TB \n",
      " Brief Info: Top variant of hig \n",
      "\n",
      "%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n",
      "Brand: Apple \n",
      " Model: iPhone 13 Pro 5G A2639 Dual SIM TD-LTE CN 512GB \n",
      " Brief Info: Super Retina XDR \n",
      "\n",
      "%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n",
      "Brand: Apple \n",
      " Model: iPhone 13 Pro 5G A2639 Dual SIM TD-LTE CN 128GB \n",
      " Brief Info: The most afforda \n",
      "\n",
      "%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n",
      "Brand: Apple \n",
      " Model: iPhone 13 Pro 5G A2639 Dual SIM TD-LTE CN 256GB \n",
      " Brief Info: iOS 15 enhances  \n",
      "\n",
      "%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n",
      "Brand: Apple \n",
      " Model: iPhone 13 Pro Max 5G A2644 Dual SIM TD-LTE CN 1TB \n",
      " Brief Info: Top variant of \n",
      "\n",
      "%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n",
      "Brand: Apple \n",
      " Model: iPhone 13 Pro Max 5G A2644 Dual SIM TD-LTE CN 128GB \n",
      " Brief Info: The most aff \n",
      "\n",
      "%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n",
      "Brand: Apple \n",
      " Model: iPhone 13 Pro Max 5G A2644 Dual SIM TD-LTE CN 256GB \n",
      " Brief Info: All-new Supe \n",
      "\n",
      "%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n",
      "Brand: Apple \n",
      " Model: iPhone 13 Pro Max 5G A2644 Dual SIM TD-LTE CN 512GB \n",
      " Brief Info: The wide-ang \n",
      "\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "Xiaomi Redmi Note 9 Pro  related texts:\n",
      "%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n",
      "Brand: Xiaomi \n",
      " Model: Redmi Note 9 Pro 5G Premium Edition Dual SIM TD-LTE CN 256GB M2007J17C \n",
      " Brie \n",
      "\n",
      "%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n",
      "Brand: Xiaomi \n",
      " Model: Redmi Note 9 Pro 5G Premium Edition Dual SIM TD-LTE CN 128GB M2007J17C \n",
      " Brie \n",
      "\n",
      "%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n",
      "Brand: Xiaomi \n",
      " Model: Redmi Note 9 Pro 5G Standard Edition Dual SIM TD-LTE CN 128GB M2007J17C \n",
      " Bri \n",
      "\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "Huawei P30  related texts:\n",
      "%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n",
      "Brand: Huawei \n",
      " Model: P30 Premium Edition Dual SIM TD-LTE CN 256GB ELE-AL00 / ELE-AL10 \n",
      " Brief Info \n",
      "\n",
      "%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n",
      "Brand: Huawei \n",
      " Model: P30 Premium Edition Dual SIM TD-LTE CN 64GB ELE-AL00  \n",
      " Brief Info: Chinese f \n",
      "\n",
      "%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n",
      "Brand: Huawei \n",
      " Model: P30 Pro Premium Edition Dual SIM TD-LTE CN VOG-AL00 128GB \n",
      " Brief Info: Chine \n",
      "\n",
      "%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n",
      "Brand: Huawei \n",
      " Model: P30 Pro Premium Edition Dual SIM TD-LTE CN VOG-AL00 256GB \n",
      " Brief Info: P30 P \n",
      "\n",
      "%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n",
      "Brand: Huawei \n",
      " Model: P30 Pro Premium Edition Dual SIM TD-LTE CN VOG-TL00 128GB \n",
      " Brief Info: China \n",
      "\n",
      "%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n",
      "Brand: Huawei \n",
      " Model: P30 Premium Edition Dual SIM TD-LTE CN 128GB ELE-TL00 \n",
      " Brief Info: China Mob \n",
      "\n",
      "%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n",
      "Brand: Huawei \n",
      " Model: P30 Pro Premium Edition Dual SIM TD-LTE CN 512GB VOG-AL00 / VOG-AL10 \n",
      " Brief  \n",
      "\n",
      "%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n",
      "Brand: Huawei \n",
      " Model: P30 Premium Edition Dual SIM TD-LTE CN 128GB ELE-AL00  \n",
      " Brief Info: Smaller  \n",
      "\n",
      "------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "#Example to query phonedb database using mix models\n",
    "\n",
    "query3 = \"Can you list the battery life for the Apple iPhone 13, Xiaomi Redmi Note 9 Pro,\\\n",
    "and Huawei P30 Pro?\"\n",
    "\n",
    "\n",
    "key_names = name_query_mix_models_inference(query3, name_list, print_process=True)\n",
    "\n",
    "print(\"\\n------------------------------------------------\")\n",
    "print(\"Querying local DataBase ......\")\n",
    "for n in key_names:\n",
    "    specs_texts = query_specs_list(n)\n",
    "    print(\"++++++++++++++++++++++++++++++++++++++++++++++++\")\n",
    "    print(n, \" related texts:\")\n",
    "    for text in specs_texts:\n",
    "        print(\"%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\")\n",
    "        print(text[0:100], \"\\n\") #only print the first 100 chars of a text\n",
    "print(\"------------------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dd87420-4e0f-49bd-bf8d-9de85c92b3ae",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
